#SoK: Fully Homomorphic Encryption Accelerators

iSINGLab, Hong Kong University of Science and Technology，Clustar，Fuzhou University

发表年份：2023

##Motivation：比较不同加速器的优缺点，比较的加速器有GPU-based，基于Intel CPU的HEXL，基于FPGA和ASIC的加速器设计。比较的指标有多项式计算模式、支持算法，可编程性，是否开源等。

##Methodology：

###主要观点：

计算开销大的原因有三点：高计算复杂度、intensive内存访问、泛化性能比较差

![image-20231214160238191](C:\Users\luhan\AppData\Roaming\Typora\typora-user-images\image-20231214160238191.png)

**计算复杂度高：**主要由FFT/NTT引起，最高可达70%，数据之间有依赖无法大规模并行。ASIC中的流水线并行（比如n=65526个数的NTT）会占用大量计算资源，使得FPGA布局布线困难。数据量大规模移动也在FPGA上不可行。所以主流加速器设计都是用4-step FFT/NTT。

**内存访问频繁：**所有的加速器设计依赖于HBM3，HBM数据搬运要比计算核的计算时间长11.7x。

![image-20231214161055076](C:\Users\luhan\AppData\Roaming\Typora\typora-user-images\image-20231214161055076.png)

此外，twiddle factors也需要存储，对于FFT，tf的数量小于输入参数的数量。**然而，对于基于RNS-NTT，每个qi都需要一组tf，造成参数膨胀。**对于4-step的NTT，需要更多的pre-computed参数，虽然4-step NTT不需要tf，但是需要一个新的参数叫**twisted factors**，也是每个RNS的qi对应一组。

**泛化能力差：**对不同的输入n，FFT/NTT的硬件需求自然不一样，这就是这篇文章所谓的泛化能力差。这个问题貌似我们的Poseidon解决了。

![image-20231214161931550](C:\Users\luhan\AppData\Roaming\Typora\typora-user-images\image-20231214161931550.png)



###比较不同加速器的特点：

![image-20231214155725195](C:\Users\luhan\AppData\Roaming\Typora\typora-user-images\image-20231214155725195.png)

####加速keyswitch：加速这个操作涉及到数据流的模式问题，因为basis conversion设计到类似MAC的操作，数据流就有不同设计方式：

rPLP：residue-polynomial level parallelism.，意思每个core处理不同的RNS分量多项式，每个core只处理自己的那1个RNS分量多项式。

CLP：coefficient-level parallelism. 意思所有core”协作“处理1个单独的RNS分量多项式，不同core处理**同一个**多项式中的n个不同系数。Poseidon是CLP

####加速自举：

作者说LSTM消耗61%的乘法深度，35 out of 57。深度学习的应用必须支持自举，也就是L要足够大，Q也要足够大。增大了开销。（自举都是这个问题）

permutations：CoefftoSlot操作pack 4096个明文需要30个同态的permutations。



##几个典型加速器的对比：重点的几个加速器特点列出来：

（1）HEAT：2019年提出，支持ARM控制数据流并且manage网络传输，使用软件作为数据流调度器，这样可以使得算数操作和keyswitch等可以combine到一起实现高性能，针对的只有BFV。只有4096多项式深度，不支持自举和可编程。

（2）HEAX：由微软于2020年提出[19]。它提供了一个高性能的硬件架构来加速CKKS的操作。HEAX不是一个开源项目。HEAX的加速基础是原始模块：NTT和乘法模块。每个模块由多个计算核心组成，这些核心可以进行调整­以匹配所需的吞吐量。

与HEAT不同，HEAT在实现密钥切换时依赖于软件来操作硬件基元运算（例如NTT和乘法），HEAX实现了特定的密钥切换模块，以最大限度地减少软件和硬件交互的开销。按照­密钥交换的工作流程，密钥交换模块实例化多个基元模块和BRAM来构建管道。可以基于特定的密码参数来调整模块以平衡流水线中的吞吐量。

然而，HEAX的调整是通过物理修改模块来完成的。FPGA必须重新配置以适应不同的密码参数，这限制了设计的通用性。

（3）F1：为了解决资源不足（例如基于FPGA的资源）和不合适的固定架构（例如基于CPU或GPU的固定架构）的问题，最近的工作已经转向探索专用集成电路（ASIC）的潜力。遵循这一趋势，Feldmann等人在2021年提出了F1[26]。为了追求更实用的FHE方案加速，F1是第一个具有专用架构的可编程FHE加速器，这­意味着它可以支持多个具有大范围密码参数的FHE计划。F1不是开源的。在其核心，F1实现了16个计算簇，每个计算簇包含几个基函数单元（FU），­包括NTT、模乘、模加和自同构。不同的单元可以组成高级FHE操作，如密钥切换。所有FU被流水线化和矢量化以在每个周期中处理128个元素。因此，可以通过将操作数顺序馈送到流水线来处理次数为128­的倍数的多项式。具体而言，为了用128元素处理器实现NTT，F1利用4步FFT/NTT算法[54]将NTT分解为具有更少输入元素的多个矢量化运算。F1试图通过提出分层存储系统来最小化数据移动开销。片外高带宽存储器（HBM）是与CPU服务器直接交互的全局存储器。在16组SRAM上构建的64MB暂存区被设计为片上高速缓存，并从HBM中提取数据。计算集群与暂存区通信，并将用于当前操作的数据存储在有限的矢量寄存器中。暂存区和集群之间的通信依赖于一个复杂的全连接网络（三个16×16的交叉开关）。F1的设计有三个主要问题。首先，F1的性能高度依赖于16个集群之间的足够并行性和加速器中的有效数据移动，这对软件编译器的操作调­度提出了很高的要求。考虑到FHE计算在不同的工作流程和不同的参数设置方面差异很大，编译器很复杂。­然而，F1并没有提供关于其编译器的许多细节。第二个问题是F1使用固定密钥切换算法（dnum=L+1的广义密钥切换）。如果密文的乘法深度L较高，则密钥切换极为缓慢。最后，F1只支持非压缩自举[45]，它只适用于多项式中包含单个数字的密文，在现实应用中远不实用。原因是F1通过4步FFT/NTT算法支持的最大多项式次数为16384，这对于F1来说太小了，无法在80位下执行完全打包的自举[71]。

（4）100x：Jung等人在2021年提出了100x[15]。它使用强大的V100 GPU­提供了比以前的工作（即HEX-FPGA和HEAX）更高的CKKS加速[69]。原因是V100由于更好的半导体制造工艺而具有更多的硬件资源，­并且工作频率远高于先前工作中采用的FP GA。100引入了以内存为中心的优化，以提高端到端性能，并与单线程CPU实现相比实现了超过100x的加速比.NTT在100x中的实现是基于[70]中的分层方法构建的。其基本思想遵循4步FFT/NTT算法[54]。NTT的实现分为两个独立的内核，从而可以将所有输入数据缓存在共享内存中。此外，由于GPU中寄存器的大小有限，两个内核都基于4步FFT/NTT算法的广义版本进一步分解NTT。除了分解之外，还利用包括联合内存访问和动态旋转因子生成在内的方案来减少内存访问的开销。然而，尽管基本操作中的内存访问已经优化，但FHE任务的端到端性能仍然受到主内存带宽的限制。为了缓解瓶颈，100×的作者倾向于将多个内核融合到一个内核中，这允许缓存在芯片上的数据被一系列连续操作重用，并减少全局内存访问。然而，由于GPU的架构是为小数字（例如FP16）之间的计算而设计的，因此它不提供大的片上存储器。因此，密集的内存访问仍然会降低100倍的性能。

（5）CraterLake: 由Samardzic等人于2022年提出[27]。这不是一个开源项目。CraterLake是­F1的后续，目标是无限深度同态­乘法。因此，CraterLake使用完全封装的自举[71]来刷新密文的乘法深度。为了平衡自举的频率和密文的大小，CraterLake的作者选择了每次同态­乘法所需的乘法器数量作为评估FHE程序总体计算复杂性的标准。此外，作者­遵循F1中矢量化单元的思想，将整个加速器逻辑设计为单个2048元素的矢量化处理器来处理大密文，这要求最大多项式次数和­乘法深度分别为65536和60。然而，考虑到复杂的组合和时序逻辑电路，这种设计不能在ASIC上天真地实现。因此，在CraterLake中，2048元素处理器在物理上由八个256元素组组成。与F1[26]类似，CraterLake­在每个256元素组中实现了几个功能单元（FU）。不同之处在于CraterLake中的两个额外FU，即更换RNS基座（CRB）和切换密钥生成器（KSHGen），这两个单元都是为了进一步优化密钥切换而引入的。CRB单元主要执行模乘­和模和，专门设计用于在dnum相对较小（例如，dnum=1）时加速快速基转换。为了节省额外的内存空间，KSHGen单元动态生成切换密钥，这些密钥在以前的工作中预先计算并缓存在设备内存中，如F1[26]和HEAX[19]。CraterLake与以前的工作的另一个主要区别是，由于快速基转换的工作量越来越大，Crater Lake采用CLP而不是rPLP作为数据并行方案。在CLP方案中，CraterLake只同时处理一个多项式运算­，并且多项式的系数以静态分布策略分布到256个元素组，这带来了三个显著的优势。首先，由于特定的系数只能分配给特定的组，因此不再需要F1中的复杂1616 纵横制，该纵横制处理片上暂存区和组之间的动态数据交换。也可以消除由不同多项式之间的运算引起的数据移动。其次，CraterLake的并行性不受不同乘法深度或并发操作数量的影响，这在整个FHE程序中保持了性能，并简化了软件调度器。尽管CraterLake的可编程性足以支持­不同的密码参数，但正如我们在[§3.1.4](#_bookmark10)[中](#_bookmark10)提到的，由于静态流水线电路，FU，尤其是NTT单元，可能面临功能限制或资源利用不足。当且仅当n=65536时，Crater Lake中的计算资源才能被充分利用，这是包含流水线NTT电路（例如F1和ARK）的工作的常见问题。此外，在CraterLake，CRB单元占据了34%的片上面积，降低了NTT等其他操作的性能。因此，在更大的dnum是最佳的情况下，CRB单元利用不足，CraterLake无法提供足够的加速度。

（6）BTS：由Kim等人于2022年提出[28]。它是100的­后续产品，与CraterLake有着相似的设计目标，即­为单词式FHE提供可引导和可编程的硬件架构。由于目标相似，­BTS中的许多优化方法都与CraterLake中的方法接近，包括基本转换单元、CLP并行方案和实时数据生成。CraterLake和BTS之间最显著的区别在于它们放置基本功能单元的模式，从而导致­基本操作的不同实现。BTS的架构接近现代GPU，由6432 个二维（2D）处理元件阵列（PE）组成。每个PE包括基转换单元和2点NTT/iNTT单元（即单个蝶形单元）。2048个PE通过垂直和水平横杆互连。具有该体系结构的131072点NTT的示例如下所示。首先，每个PE­独立地执行64点NTT。第二，同一行中的64个PE通过水平交叉开关执行具有数据同步的64点NTT。第三，同一列中的32个PE通过垂直交叉开关执行具有数据同步的32点NTT。该过程推广了四步FFT/NTT算法。每个PE扮演着与GPU线程相似的角色，交叉开关实现线程同步。为了促进独特的计算模式，作者在每个PE中放置了多个较小的本地草稿簿，而不是放置一个与所有PE通信的大型全局草稿簿。本地暂存区直接与HBM连接，消除了分层数据分布带来的额外开销。然而，BTS的一个潜在缺点是2D阵列结构不能以完全流水线的工作流程执行NTT。如前所述，BTS中的NTT操作由三个顺序步骤组成，并且所有PE都参与到每个步骤中。因此，如果要处理多个NTT操作，则无法实现流水线并行，这可能会降低端到端性能。与F1和CrateLake类似，BTS也不是开源的。

（7）ARK由Kim等人于2022年提出[29]。它由四个矢量化处理集群组成，类似于火山口湖的256个元素组。每个集群包含几个­主要操作单元。与以往仅从硬件角度针对加速自举的工作不同[27]，[28]，ARK是第一个对自举算法进行分析和修改的工作，从而实现了优化加速器性能的算法和硬件协同设计。具体而言，作者分别提出了多跳同态旋转和动态残差扩展，以显著减少自举中使用的切换密钥和纯文本的大小，从而降低了硬件设计中的困难。如本节前面所述，在自举过程中，基转换的工作量很大，这使得CLP成为CraterLake和BTS等可自举加速器的首选并行方案。但是CLP也在NTT中引入了通信开销。根据ARK，在给定实际­可引导参数的情况下，NTT和基转换分别占总计算工作量的54.8%和34.2%。由于这两种功能对端到端性能都至关重要，ARK利用这两种方案，即CLP用于基转换，rPLP用于包括NTT在内的其他操作。ARK还使用两种数据分布模式之间的切换机制，特别是对于同时包含NTT和基转换的函数，例如密钥切换。在ARK的论文中，这种混合并行性被证明比rPLP更有效，但它是否比CLP更好没有讨论。

###总结几点观察：

（1）越来越往ASIC上发展。不受资源限制，但是耗资巨大。

（2）SW/HW Co-design：![image-20231214165341281](C:\Users\luhan\AppData\Roaming\Typora\typora-user-images\image-20231214165341281.png)

（3）增加可编程性：不同加速器都有资源利用率低的问题，需要增加可编程性让硬件适配不同的参数配置。比如keyswitch在不同RNS分量数的时候就有不用的利用率问题。同时密钥要on-the-fly的产生

#未来趋势：

（1）针对应用设计专用加速器而不是仅仅FHE的算法。比如ISCA一个论文讲PSI的算法硬件实现。减少存储和FHE加速器的数据搬运。

（2）两种算法的结合加速器没有，CKKS+TFHE

（3）编译器设计：软硬件协同。设计一个cost model，进行优化

（4）多卡：单卡片上下的数据搬运开销大，多卡间数据开销是否可以比单卡数据搬运的开销小？只要把network controller设计好

（5）NTRU



#几个问题没搞明白：

这里RNS分量可以几个分量1个qi么？

![image-20231214170447796](C:\Users\luhan\AppData\Roaming\Typora\typora-user-images\image-20231214170447796.png)

![image-20231214170557662](C:\Users\luhan\AppData\Roaming\Typora\typora-user-images\image-20231214170557662.png)

![image-20231214170626464](C:\Users\luhan\AppData\Roaming\Typora\typora-user-images\image-20231214170626464.png)